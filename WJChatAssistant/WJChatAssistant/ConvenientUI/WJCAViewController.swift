//
//  WJCAViewController.swift
//  WJChatAssistant
//
//  Created by wangjian on 28/05/2018.
//  Copyright Â© 2018 wangjian. All rights reserved.
//

import Foundation

open class WJCAViewController: UIViewController {
    
    public let chatAssistant = WJChatAssistant.default
    public weak var delegate: WJCAViewControllerDelegate? = nil
    public weak var datasource: WJCAViewControllerDatasource? = nil
    
    private var messages: [WJCADialogMessage] = [
//    {
//        var msg = WJCADialogMessage()
//        msg.content = "Hiï¼Œå°ç’‡"
//        msg.speaker = .user
//        return msg
//        }(),
//    {
//        var msg = WJCADialogMessage()
//        msg.content = "æˆ‘åœ¨å‘¢ï¼Œæœ‰ä»€ä¹ˆäº‹å—ï¼Ÿ"
//        msg.speaker = .bot
//        return msg
//        }(),
//    {
//        var msg = WJCADialogMessage()
//        msg.content = "æ²¡ä»€ä¹ˆäº‹å„¿ï¼Œå°±æ˜¯æƒ³æ‰¾ä½ é—²èŠä¸€ä¸‹ï¼Œä½ çŽ°åœ¨æœ‰æ—¶é—´ä¹ˆï¼Ÿ"
//        msg.speaker = .user
//        return msg
//        }(),
//    {
//        var msg = WJCADialogMessage()
//        msg.content = ""
//        msg.speaker = .bot
//        msg.status = .processing
//        return msg
//        }(),
//    {
//        var msg = WJCADialogMessage()
//        msg.contentType = .image
//        msg.content = #imageLiteral(resourceName: "test_img1")
//        msg.speaker = .bot
//        return msg
//        }(),
//    {
//        var msg = WJCADialogMessage()
//        msg.contentType = .image
//        msg.content = #imageLiteral(resourceName: "test_img2")
//        msg.speaker = .user
//        return msg
//        }(),
//    {
//        var msg = WJCADialogMessage()
//        msg.contentType = .options
//        msg.content = {
//            var content = WJCADialogOptionMessageContent()
//            content.title = "æˆ‘å¯ä»¥è¿™æ ·åšä¹ˆ"
//            content.options = ["æ˜¯", "å¦"]
//            return content
//        }()
//        msg.speaker = .bot
//        return msg
//        }(),
//    {
//        var msg = WJCADialogMessage()
//        msg.contentType = .optionsList
//        msg.content = {
//            var content = WJCADialogOptionMessageContent()
//            content.title = "æˆ‘æ‰¾åˆ°äº†ä»¥ä¸‹é€‰é¡¹"
//            content.options = ["æˆ‘æ¯”è¾ƒçŸ­", "æˆ‘æ˜¯ä¸€ä¸ªå¾ˆé•¿å¾ˆé•¿å¾ˆé•¿å¾ˆé•¿å¾ˆé•¿å¾ˆé•¿å¾ˆé•¿å¾ˆé•¿å¾ˆé•¿çš„æŒ‰é’®", "çŸ­", "ä¸€èˆ¬èˆ¬å§", "åˆæ˜¯ä¸€ä¸ªæ¯”è¾ƒé•¿çš„æŒ‰é’®å™¢å™¢å™¢å™¢", "uuuuu", "222222"]
//            return content
//        }()
//        msg.speaker = .bot
//        return msg
//        }(),
//    {
//        var msg = WJCADialogMessage()
//        msg.content = ""
//        msg.speaker = .bot
//        msg.status = .processing
//        return msg
//        }(),
//    {
//        var msg = WJCADialogMessage()
//        msg.contentType = .optionsList
//        msg.content = {
//            var content = WJCADialogOptionMessageContent()
//            content.title = "æˆ‘æ‰¾åˆ°äº†ä»¥ä¸‹é€‰é¡¹"
//            content.options = ["æˆ‘æ¯”è¾ƒçŸ­", "æˆ‘æ˜¯ä¸€ä¸ªå¾ˆé•¿å¾ˆé•¿å¾ˆé•¿å¾ˆé•¿å¾ˆé•¿å¾ˆé•¿å¾ˆé•¿å¾ˆé•¿å¾ˆé•¿çš„æŒ‰é’®", "çŸ­", "ä¸€èˆ¬èˆ¬å§", "åˆæ˜¯ä¸€ä¸ªæ¯”è¾ƒé•¿çš„æŒ‰é’®å™¢å™¢å™¢å™¢", "uuuuu", "222222"]
//            return content
//        }()
//        msg.speaker = .bot
//        return msg
//        }(),
//    {
//        var msg = WJCADialogMessage()
//        msg.contentType = .optionsList
//        msg.content = {
//            var content = WJCADialogOptionMessageContent()
//            content.title = "æˆ‘æ‰¾åˆ°äº†ä»¥ä¸‹é€‰é¡¹"
//            content.options = ["æˆ‘æ¯”è¾ƒçŸ­", "uuuuu", "222222"]
//            return content
//        }()
//        msg.speaker = .user
//        return msg
//        }()
    ]
    
    private lazy var dialogView: WJCADialogView = {
        let dialogView = WJCADialogView(frame: .zero)
        dialogView.delegate = self
        dialogView.dataSource = self
        return dialogView
    }()
    
    private lazy var funtionBar: WJCAFunctionBar = {
        let bar = WJCAFunctionBar.init(frame: .zero)
        
        bar.delegate = self
        bar.datasource = self
        return bar
    }()
    
    private var speechRecognitionResult: WJSpeechRecognitionResult? = nil
    
    // MARK: - Life cycle
    open override func viewDidLoad() {
        super.viewDidLoad()
        
        chatAssistant.delegate = self
        view.backgroundColor = .white
        
        view.addSubview(dialogView)
        view.addSubview(funtionBar)
        
        dialogView.translatesAutoresizingMaskIntoConstraints = false
        funtionBar.translatesAutoresizingMaskIntoConstraints = false
        
        view.addConstraint(NSLayoutConstraint(item: dialogView, attribute: .left, relatedBy: .equal, toItem: view, attribute: .left, multiplier: 1.0, constant: 0.0))
        view.addConstraint(NSLayoutConstraint(item: dialogView, attribute: .right, relatedBy: .equal, toItem: view, attribute: .right, multiplier: 1.0, constant: 0.0))
        view.addConstraint(NSLayoutConstraint(item: dialogView, attribute: .top, relatedBy: .equal, toItem: view, attribute: .top, multiplier: 1.0, constant: 0.0))
        view.addConstraint(NSLayoutConstraint(item: dialogView, attribute: .bottom, relatedBy: .equal, toItem: view, attribute: .bottom, multiplier: 1.0, constant: 0.0))
        
        let constraintTarget: Any
        if #available(iOS 11.0, *) {
            constraintTarget = view.safeAreaLayoutGuide
        }
        else {
            constraintTarget = view
        }
        view.addConstraint(NSLayoutConstraint(item: funtionBar, attribute: .left, relatedBy: .equal, toItem: view, attribute: .left, multiplier: 1.0, constant: 0.0))
        view.addConstraint(NSLayoutConstraint(item: funtionBar, attribute: .right, relatedBy: .equal, toItem: view, attribute: .right, multiplier: 1.0, constant: 0.0))
        view.addConstraint(NSLayoutConstraint(item: funtionBar, attribute: .top, relatedBy: .equal, toItem: constraintTarget, attribute: .bottom, multiplier: 1.0, constant: -funtionBar.suggestHeight))
        view.addConstraint(NSLayoutConstraint(item: funtionBar, attribute: .bottom, relatedBy: .equal, toItem: view, attribute: .bottom, multiplier: 1.0, constant: 0.0))
        
        var contentInset = UIEdgeInsets(top: 0, left: 0, bottom: funtionBar.suggestHeight, right: 0)
        if #available(iOS 11.0, *) {
            contentInset.bottom += view.safeAreaInsets.bottom
        }
        dialogView.contentInset = contentInset
    }
}

// MARK: - WJChatAssistantDelegate
extension WJCAViewController: WJChatAssistantDelegate {
    
    public func wjChatAssistantSpeechRecognizeComplate(_ isSuceessful: Bool, _ error: NSError?) {
        funtionBar.stopRecording()
        
        if let speechRecognitionResult = speechRecognitionResult, isSuceessful {
            var msg = WJCADialogMessage()
            msg.content = speechRecognitionResult.bestTranscription
            msg.speaker = .user
            messages.append(msg)
            
            dialogView.appendMsg()
            
            
            var msg1 = WJCADialogMessage()
            msg1.content = WJCADialogOptionMessageContent()
            msg1.speaker = .bot
            msg1.contentType = .optionsList
            msg1.status = .processing
            messages.append(msg1)
            dialogView.appendMsg()
            
            chatAssistant.intentRecognizer?.recognize(text: speechRecognitionResult.bestTranscription) {
                (intent, error) in
                guard let intent = intent else { return }
                
                let index = self.messages.count-1
                let isIntentClear = intent.topScoringIntent.score >= 0.85
                var msg = WJCADialogMessage()
                msg.speaker = self.messages[index].speaker
                if isIntentClear {
                    msg.contentType = .options
                    msg.content = WJCADialogOptionMessageContent(title: "ðŸ‘Œï¼Œæ²¡é—®é¢˜ã€‚", options: [intent.topScoringIntent.intent])
                }
                else {
                    msg.contentType = .optionsList
                    let top5 = Array(intent.intents.prefix(5))
                    msg.content = WJCADialogOptionMessageContent(title: "ä½ æ˜¯æƒ³ï¼š", options: top5.map({ (intent) -> String in
                        return intent.intent
                    }))
                }
                self.messages[index] = msg
                
                DispatchQueue.main.async {
                self.dialogView.updateMsg(at: index)
                }
            }
        }
    }
    
    public func wjChatAssistantUpdateVoicePower(_ averagePower: Float?, peakPower: Float?) {
        funtionBar.recordingController.updateVoicePower(peakPower)
    }
    
    public func wjChatAssistantUpdateSpeechRecognizeResult(_ result: WJSpeechRecognitionResult) {
        funtionBar.recordingController.textContent = result.bestTranscription
        speechRecognitionResult = result
    }
    
    
}

// MARK: - WJCADialogViewDatasource
extension WJCAViewController: WJCADialogViewDataSource {
    
    public func numberOfMessage(inDialogView dialogView: WJCADialogView) -> Int {
        return messages.count
    }
    
    public func dialogView(_ dialogView: WJCADialogView, messageAtIndex index: Int) -> WJCADialogMessage {
        return messages[index]
    }
}

// MARK: - WJCADialogViewDelagate
extension WJCAViewController: WJCADialogViewDelagate {
    
    public func didSelectOption(inMessage msgIndex: Int, at optionIndex: Int) {
        guard let content = messages[msgIndex].content as? WJCADialogOptionMessageContent else {
            return
        }
        delegate?.needExcusIntent(content.options[optionIndex])
    }
}

// MARK: - WJCAFunctionBarDatasource
extension WJCAViewController: WJCAFunctionBarDatasource {
    
    
}

// MARK: - WJCAFunctionBarDelegate
extension WJCAViewController: WJCAFunctionBarDelegate {
    
    public func shouldStartRecording() {
        speechRecognitionResult = nil
        funtionBar.startRecording()
        if !isSimulator() {
        chatAssistant.startListen()
    }
    }
    
    public func shouldCancelRecording() {
        chatAssistant.cancelListen()
        funtionBar.stopRecording()
    }
    
    public func shouldEndRecording() {
        
        if isSimulator() {
            let msg = messages.count > 1 ? "ä½ å¥½" : "æˆ‘è¦ä¸Šç­æ‰“å¡"
            speechRecognitionResult = WJSpeechRecognitionResult(bestTranscription: msg, transcriptions: ["ä½ å¥½"], isFinal: true)
            wjChatAssistantSpeechRecognizeComplate(true, nil)
        } else {
            chatAssistant.stopListen()
        }
    }
    
    public func shouldStartTyping() {
        
    }
    
    public func shouldCancelTyping() {
        
    }
    
    public func shouldEndTyping() {
        
    }
    
    
}

func isSimulator() -> Bool {
    var isSim = false
    #if arch(i386) || arch(x86_64)
        isSim = true
    #endif
    return isSim
}

